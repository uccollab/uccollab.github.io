---
---

@inproceedings{atzori2018unsupervised,
  title={Unsupervised singleton expansion from free text},
  author={Atzori, Maurizio and Balloccu, Simone and Bellanti, Andrea},
  booktitle={2018 IEEE 12th International Conference on Semantic Computing (ICSC)},
  pages={180--185},
  year={2018},
  month={Jan-Feb},
  organization={IEEE}
}

@inproceedings{atzori2019okgraph,
  title={OKgraph: Unsupervised Structured Data Extraction from Plain Text.},
  author={Atzori, Maurizio and Balloccu, Simone and Bellanti, Andrea and Mameli, Emanuele and Usai, Stefano Raimondo},
  booktitle={10th Italian Information Retrieval Workshop (IIR 2019)},
  month={Sept},
  year={2019}
}

@inproceedings{balloccu2020nlg,
  title={A NLG Framework for User Tailoring and Profiling in Healthcare.},
  author={Balloccu, Simone and Pauws, Steffen and Reiter, Ehud},
  booktitle={1st Workshop on Smart Personal Health Interfaces (SmartPhil)@IUI},
  pages={13--32},
  month={Mar},
  year={2020}
}

@article{atzori2020fully,
  title={Fully-unsupervised embeddings-based hypernym discovery},
  author={Atzori, Maurizio and Balloccu, Simone},
  journal={Information},
  volume={11},
  number={5},
  pages={268},
  month={May},
  year={2020},
  publisher={MDPI},
  abstract="The hypernymy relation is the one occurring between an instance term and its general term (e.g., ‚Äúlion‚Äù and ‚Äúanimal‚Äù, ‚ÄúItaly‚Äù and ‚Äúcountry‚Äù). This paper we addresses Hypernym Discovery, the NLP task that aims at finding valid hypernyms from words in a given text, proposing HyperRank, an unsupervised approach that therefore does not require manually-labeled training sets as most approaches in the literature. The proposed algorithm exploits the cosine distance of points in the vector space of word embeddings, as already proposed by previous state of the art approaches, but the ranking is then corrected by also weighting word frequencies and the absolute level of similarity, which is expected to be similar when measuring co-hyponyms and their common hypernym. This brings us two major advantages over other approaches‚Äî(1) we correct the inadequacy of semantic similarity which is known to cause a significant performance drop and (2) we take into accounts multiple words if provided, allowing to find common hypernyms for a set of co-hyponyms‚Äîa task ignored in other systems but very useful when coupled with set expansion (that finds co-hyponyms automatically). We then evaluate HyperRank against the SemEval 2018 Hypernym Discovery task and show that, regardless of the language or domain, our algorithm significantly outperforms all the existing unsupervised algorithms and some supervised ones as well. We also evaluate the algorithm on a new dataset to measure the improvements when finding hypernyms for sets of words instead of singletons."
}

@inproceedings{balloccu2020you,
  title={How are you? Introducing stress-based text tailoring},
  author={Balloccu, Simone and Reiter, Ehud and Johnstone, Alexandra and Fyfe, Claire},
  booktitle={Proceedings of the Workshop on Intelligent Information Processing and Natural Language Generation (IntelLanG)@ECAI 2020},
  pages={62--70},
  month={Sept},
  year={2020}
}

@inproceedings{10.1145/3450614.3463602,
author = {Balloccu, Simone and Reiter, Ehud and Collu, Matteo G. and Sanna, Federico and Sanguinetti, Manuela and Atzori, Maurizio},
title = {Unaddressed challenges in persuasive dieting chatbots},
year = {2021},
isbn = {9781450383677},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3450614.3463602},
doi = {10.1145/3450614.3463602},
abstract = {Diet coaching is a behaviour change task which requires lots of interaction with patients. E-health apps gathered lots of interest in research and, recently, chatbots have been leveraged to address this task, with a focus on persuasion to motivate people towards behaviour change. In this paper, we take a look at current approaches in building persuasive dieting chatbots and expose a number of major unsolved challenges. We motivate them with evidence from previous work and show that current chatbots don‚Äôt approach certain scenarios properly, hence limiting their communication and persuasion capabilities.},
booktitle = {Adjunct Proceedings of the 29th ACM Conference on User Modeling, Adaptation and Personalization},
pages = {392‚Äì395},
numpages = {4},
keywords = {challenges, chatbots, conversational agents, diet, diet coaching, natural language generation, persuasion},
location = {Utrecht, Netherlands},
series = {UMAP '21}
}



@inproceedings{sdaih23,
author="Kumar, Vivek and Balloccu, Simone and Wu, Zixiu and Reiter, Ehud and Helaoui, Rim and Reforgiato Recupero, Diego and Riboni, Daniele",
title="Data Augmentation for Reliability and Fairness in Counselling Quality Classification",
booktitle="Proceedings of the 1st Workshop on Scarce Data in Artificial Intelligence for Healthcare - SDAIH @ IJCAI 2022",
year="2022",
month="Jul",
pages="23-28",
publisher="SciTePress",
organization="INSTICC",
doi={10.5220/0011531400003523},
isbn={978-989-758-629-3},
}

@inproceedings{balloccu-reiter-2022-beyond,
    title = "Beyond calories: evaluating how tailored communication reduces emotional load in diet-coaching",
    author = "Balloccu, Simone  and
      Reiter, Ehud",
    booktitle = "Proceedings of the 2nd Workshop on Human Evaluation of NLP Systems (HumEval)",
    month = "May",
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.humeval-1.5",
    doi = "10.18653/v1/2022.humeval-1.5",
    pages = "42--53",
    abstract = "Dieting is a behaviour change task that is difficult for many people to conduct successfully. This is due to many factors, including stress and cost. Mobile applications offer an alternative to traditional coaching. However, previous work on apps evaluation only focused on dietary outcomes, ignoring users{'} emotional state despite its influence on eating habits. In this work, we introduce a novel evaluation of the effects that tailored communication can have on the emotional load of dieting. We implement this by augmenting a traditional diet-app with affective NLG, text-tailoring and persuasive communication techniques. We then run a short 2-weeks experiment and check dietary outcomes, user feedback of produced text and, most importantly, its impact on emotional state, through PANAS questionnaire. Results show that tailored communication significantly improved users{'} emotional state, compared to an app-only control group.",
}

@INPROCEEDINGS{9746035,
  selected = {true},
  author={Wu, Zixiu and Balloccu, Simone and Kumar, Vivek and Helaoui, Rim and Reiter, Ehud and Reforgiato Recupero, Diego and Riboni, Daniele},
  booktitle={ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Anno-MI: A Dataset of Expert-Annotated Counselling Dialogues}, 
  year={2022},
  volume={},
  number={},
  pages={6177-6181},
  keywords={Employee welfare;Annotations;Conferences;Medical treatment;Signal processing;Data collection;Natural language processing;Counselling;Motivational Interviewing;Dialogue;Natural Language Processing;Dataset},
  doi={10.1109/ICASSP43922.2022.9746035}}

@inproceedings{balloccu-reiter-2022-comparing,
    title = "Comparing informativeness of an {NLG} chatbot vs graphical app in diet-information domain",
    author = "Balloccu, Simone  and
      Reiter, Ehud",
    booktitle = "Proceedings of the 15th International Conference on Natural Language Generation",
    month = "Jul",
    year = "2022",
    address = "Waterville, Maine, USA and virtual meeting",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.inlg-main.13",
    pages = "156--185",
    abstract = "Visual representation of data like charts and tables can be challenging to understand for readers. Previous work showed that combining visualisations with text can improve the communication of insights in static contexts, but little is known about interactive ones. In this work we present an NLG chatbot that processes natural language queries and provides insights through a combination of charts and text. We apply it to nutrition, a domain communication quality is critical. Through crowd-sourced evaluation we compare the informativeness of our chatbot against traditional, static diet-apps. We find that the conversational context significantly improved users' understanding of dietary data in various tasks, and that users considered the chatbot as more useful and quick to use than traditional apps.",
}

@inproceedings{wu-etal-2022-towards-context,
    title = "Towards In-Context Non-Expert Evaluation of Reflection Generation for Counselling Conversations",
    author = "Wu, Zixiu  and
      Balloccu, Simone  and
      Helaoui, Rim  and
      Recupero, Diego Reforgiato  and
      Riboni, Daniele",
    booktitle = "Proceedings of the 2nd Workshop on Natural Language Generation, Evaluation, and Metrics (GEM)",
    month = "Dec",
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.gem-1.9",
    doi = "10.18653/v1/2022.gem-1.9",
    pages = "116--124",
    abstract = "Reflection is an essential counselling strategy, where the therapist listens actively and responds with their own interpretation of the client{'}s words. Recent work leveraged pre-trained language models (PLMs) to approach reflection generation as a promising tool to aid counsellor training. However, those studies used limited dialogue context for modelling and simplistic error analysis for human evaluation. In this work, we take the first step towards addressing those limitations. First, we fine-tune PLMs on longer dialogue contexts for reflection generation. Then, we collect free-text error descriptions from non-experts about generated reflections, identify common patterns among them, and accordingly establish discrete error categories using thematic analysis. Based on this scheme, we plan for future work a mass non-expert error annotation phase for generated reflections followed by an expert-based validation phase, namely {``}whether a coherent and consistent response is a good reflection{''}.",
}

@article{wu2023creation,
  title={Creation, Analysis and Evaluation of AnnoMI, a Dataset of Expert-Annotated Counselling Dialogues},
  author={Wu, Zixiu and Balloccu, Simone and Kumar, Vivek and Helaoui, Rim and Reforgiato Recupero, Diego and Riboni, Daniele},
  journal={Future Internet},
  volume={15},
  number={3},
  pages={110},
  month={March},
  year={2023},
  publisher={MDPI}
}

@INPROCEEDINGS{10193140,
  author={Susaiyah, Allmin and H√§rm√§, Aki and Balloccu, Simone and Reiter, Ehud and Petkoviƒá, Milan},
  booktitle={2023 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW)}, 
  title={Smart Selection of Useful Insights from Wearables}, 
  year={2023},
  month={June},
  volume={},
  number={},
  pages={1-4},
  doi={10.1109/ICASSPW59220.2023.10193140}
}

@inproceedings{wu-etal-2023-experts,
    title = "Are Experts Needed? On Human Evaluation of Counselling Reflection Generation",
    author = "Wu, Zixiu  and
      Balloccu, Simone  and
      Reiter, Ehud  and
      Helaoui, Rim  and
      Reforgiato Recupero, Diego  and
      Riboni, Daniele",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = "Jul",
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.382",
    doi = "10.18653/v1/2023.acl-long.382",
    pages = "6906--6930",
    abstract = "Reflection is a crucial counselling skill where the therapist conveys to the client their interpretation of what the client said. Language models have recently been used to generate reflections automatically, but human evaluation is challenging, particularly due to the cost of hiring experts. Laypeople-based evaluation is less expensive and easier to scale, but its quality is unknown for reflections. Therefore, we explore whether laypeople can be an alternative to experts in evaluating a fundamental quality aspect: coherence and context-consistency. We do so by asking a group of laypeople and a group of experts to annotate both synthetic reflections and human reflections from actual therapists. We find that both laypeople and experts are reliable annotators and that they have moderate-to-strong inter-group correlation, which shows that laypeople can be trusted for such evaluations. We also discover that GPT-3 mostly produces coherent and consistent reflections, and we explore changes in evaluation results when the source of synthetic reflections changes to GPT-3 from the less powerful GPT-2.",
}

@inproceedings{balloccu-etal-2024-leak,
    selected={true},
    title = "Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source {LLM}s (Best Non Publicized Paper Award üéñÔ∏è)",
    author = "Balloccu, Simone  and
      Schmidtov{\'a}, Patr{\'\i}cia  and
      Lango, Mateusz  and
      Dusek, Ondrej",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.eacl-long.5",
    pages = "67--93",
    abstract = "Natural Language Processing (NLP) research is increasingly focusing on the use of Large Language Models (LLMs), with some of the most popular ones being either fully or partially closed-source. The lack of access to model details, especially regarding training data, has repeatedly raised concerns about data contamination among researchers. Several attempts have been made to address this issue, but they are limited to anecdotal evidence and trial and error. Additionally, they overlook the problem of indirect data leaking, where modelsare iteratively improved by using data coming from users. In this work, we conduct the first systematic analysis of work using OpenAI{'}s GPT-3.5 and GPT-4, the most prominently used LLMs today, in the context of data contamination. By analysing 255 papers and considering OpenAI{'}s data usage policy, we extensively document the amount of data leaked to these models during the first year after the model{'}s release. We report that these models have been globally exposed to ‚àº4.7M samples from 263 benchmarks. At the same time, we document a number of evaluation malpractices emerging in the reviewed papers, such as unfair or missing baseline comparisons and reproducibility issues. We release our results as a collaborative project on https://leak-llm.github.io/, where other researchers can contribute to our efforts.",
}

@inproceedings{lango-etal-2024-reprohum,
    title = "{R}epro{H}um {\#}0043-4: Evaluating Summarization Models: investigating the impact of education and language proficiency on reproducibility",
    author = "Lango, Mateusz  and
      Schmidtova, Patricia  and
      Balloccu, Simone  and
      Dusek, Ondrej",
    editor = "Balloccu, Simone  and
      Belz, Anya  and
      Huidrom, Rudali  and
      Reiter, Ehud  and
      Sedoc, Joao  and
      Thomson, Craig",
    booktitle = "Proceedings of the Fourth Workshop on Human Evaluation of NLP Systems (HumEval) @ LREC-COLING 2024",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.humeval-1.20",
    pages = "229--237",
    abstract = "In this paper, we describe several reproductions of a human evaluation experiment measuring the quality of automatic dialogue summarization (Feng et al., 2021). We investigate the impact of the annotators{'} highest level of education, field of study, and native language on the evaluation of the informativeness of the summary. We find that the evaluation is relatively consistent regardless of these factors, but the biggest impact seems to be a prior specific background in natural language processing (as opposed to, e.g. a background in computer sci- ence). We also find that the experiment setup (asking for single vs. multiple criteria) may have an impact on the results.",
}

@inproceedings{kasner-etal-2024-factgenie-framework,
    title = "factgenie: A Framework for Span-based Evaluation of Generated Texts",
    author = "Kasner, Zden{\v{e}}k  and
      Platek, Ondrej  and
      Schmidtova, Patricia  and
      Balloccu, Simone  and
      Dusek, Ondrej",
    editor = "Mahamood, Saad  and
      Minh, Nguyen Le  and
      Ippolito, Daphne",
    booktitle = "Proceedings of the 17th International Natural Language Generation Conference: System Demonstrations",
    month = sep,
    year = "2024",
    address = "Tokyo, Japan",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.inlg-demos.5",
    pages = "13--15",
    abstract = "We present {`}factgenie{`}: a framework for annotating and visualizing word spans in textual model outputs. Annotations can capture various span-based phenomena such as semantic inaccuracies or irrelevant text. With {`}factgenie{`}, the annotations can be collected both from human crowdworkers and large language models. Our framework consists of a web interface for data visualization and gathering text annotations, powered by an easily extensible codebase.",
}

@inproceedings{schmidtova-etal-2024-automatic-metrics,
    title = "Automatic Metrics in Natural Language Generation: A survey of Current Evaluation Practices (Best Evaluation Paper Award üéñÔ∏è)",
    author = "Schmidtova, Patricia  and
      Mahamood, Saad  and
      Balloccu, Simone  and
      Dusek, Ondrej  and
      Gatt, Albert  and
      Gkatzia, Dimitra  and
      Howcroft, David M.  and
      Platek, Ondrej  and
      Sivaprasad, Adarsa",
    editor = "Mahamood, Saad  and
      Minh, Nguyen Le  and
      Ippolito, Daphne",
    booktitle = "Proceedings of the 17th International Natural Language Generation Conference",
    month = sep,
    year = "2024",
    address = "Tokyo, Japan",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.inlg-main.44",
    pages = "557--583",
    abstract = "Automatic metrics are extensively used to evaluate Natural Language Processing systems. However, there has been increasing focus on how the are used and reported by practitioners within the field. In this paper, we have conducted a survey on the use of automatic metrics, focusing particularly on natural language generation tasks. We inspect which metrics are used as well as why they are chosen and how their use is reported. Our findings from this survey reveal significant shortcomings, including inappropriate metric usage, lack of implementation details and missing correlations with human judgements. We conclude with recommendations that we believe authors should follow to enable more rigour within the field.",
}

@inproceedings{balloccu-etal-2024-ask,
    title = "Ask the experts: sourcing a high-quality nutrition counseling dataset through Human-{AI} collaboration",
    selected={true},
    author = "Balloccu, Simone  and
      Reiter, Ehud  and
      Li, Karen Jia-Hui  and
      Sargsyan, Rafael  and
      Kumar, Vivek  and
      Reforgiato, Diego  and
      Riboni, Daniele  and
      Dusek, Ondrej",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.674",
    pages = "11519--11545",
    abstract = "Large Language Models (LLMs) are being employed by end-users for various tasks, including sensitive ones such as health counseling, disregarding potential safety concerns. It is thus necessary to understand how adequately LLMs perform in such domains. We conduct a case study on ChatGPT in nutrition counseling, a popular use-case where the model supports a user with their dietary struggles. We crowd-source real-world diet-related struggles, then work with nutrition experts to generate supportive text using ChatGPT. Finally, experts evaluate the safety and text quality of ChatGPT{'}s output. The result is the HAI-coaching dataset, containing {\textasciitilde}2.4K crowdsourced dietary struggles and {\textasciitilde}97K corresponding ChatGPT-generated and expert-annotated supportive texts. We analyse ChatGPT{'}s performance, discovering potentially harmful behaviours, especially for sensitive topics like mental health. Finally, we use HAI-coaching to test open LLMs on various downstream tasks, showing that even the latest models struggle to achieve good performance. HAI-coaching is available at https://github.com/uccollab/hai-coaching/",
}

@inproceedings{schmidtova-etal-2025-eyes,
    title = "Do My Eyes Deceive Me? A Survey of Human Evaluations of Hallucinations in {NLG}",
    author = "Schmidtova, Patricia  and
      Cal{\`o}, Eduardo  and
      Balloccu, Simone  and
      Gkatzia, Dimitra  and
      Huidrom, Rudali  and
      Lango, Mateusz  and
      Same, Fahime  and
      Zouhar, Vil{\'e}m  and
      Mahamood, Saad  and
      Dusek, Ondrej",
    editor = "Flek, Lucie  and
      Narayan, Shashi  and
      Ph∆∞∆°ng, L{\^e} H·ªìng  and
      Pei, Jiahuan",
    booktitle = "Proceedings of the 18th International Natural Language Generation Conference",
    month = oct,
    year = "2025",
    address = "Hanoi, Vietnam",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.inlg-main.4/",
    pages = "60--79",
    abstract = "Hallucinations are one of the most pressing challenges for large language models (LLMs). While numerous methods have been proposed to detect and mitigate them automatically, human evaluation continues to serve as the gold standard. However, these human evaluations of hallucinations show substantial variation in definitions, terminology, and evaluation practices. In this paper, we survey 64 studies involving human evaluation of hallucination published between 2019 and 2024, to investigate how hallucinations are currently defined and assessed. Our analysis reveals a lack of consistency in definitions and exposes several concerning methodological shortcomings. Crucial details, such as evaluation guidelines, user interface design, inter-annotator agreement metrics, and annotator demographics, are frequently under-reported or omitted altogether."
}

@inproceedings{li-etal-2025-llms-cant,
    title = "When {LLM}s Can{'}t Help: Real-World Evaluation of {LLM}s in Nutrition",
    author = "Li, Karen Jia-Hui  and
      Balloccu, Simone  and
      Dusek, Ondrej  and
      Reiter, Ehud",
    editor = "Flek, Lucie  and
      Narayan, Shashi  and
      Ph∆∞∆°ng, L{\^e} H·ªìng  and
      Pei, Jiahuan",
    booktitle = "Proceedings of the 18th International Natural Language Generation Conference",
    month = oct,
    year = "2025",
    address = "Hanoi, Vietnam",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.inlg-main.44/",
    pages = "753--779",
    abstract = "The increasing trust in large language models (LLMs), especially in the form of chatbots, is often undermined by the lack of their extrinsic evaluation. This holds particularly true in nutrition, where randomised controlled trials (RCTs) are the gold standard, and experts demand them for evidence-based deployment. LLMs have shown promising results in this field, but these are limited to intrinsic setups. We address this gap by running the first RCT involving LLMs for nutrition. We augment a rule-based chatbot with two LLM-based features: (1) message rephrasing for conversational variety and engagement, and (2) nutritional counselling through a fine-tuned model. In our seven-week RCT (n=81), we compare chatbot variants with and without LLM integration. We measure effects on dietary outcome, emotional well-being, and engagement. Despite our LLM-based features performing well in intrinsic evaluation, we find that they did not yield consistent benefits in real-world deployment. These results highlight critical gaps between intrinsic evaluations and real-world impact, emphasising the need for interdisciplinary, human-centred approaches."
}




