---
---

@inproceedings{atzori2018unsupervised,
  title={Unsupervised singleton expansion from free text},
  author={Atzori, Maurizio and Balloccu, Simone and Bellanti, Andrea},
  booktitle={2018 IEEE 12th International Conference on Semantic Computing (ICSC)},
  pages={180--185},
  year={2018},
  month={Jan-Feb},
  organization={IEEE}
}

@inproceedings{atzori2019okgraph,
  title={OKgraph: Unsupervised Structured Data Extraction from Plain Text.},
  author={Atzori, Maurizio and Balloccu, Simone and Bellanti, Andrea and Mameli, Emanuele and Usai, Stefano Raimondo},
  booktitle={10th Italian Information Retrieval Workshop (IIR 2019)},
  month={Sept},
  year={2019}
}

@inproceedings{balloccu2020nlg,
  title={A NLG Framework for User Tailoring and Profiling in Healthcare.},
  author={Balloccu, Simone and Pauws, Steffen and Reiter, Ehud},
  booktitle={1st Workshop on Smart Personal Health Interfaces (SmartPhil)@IUI},
  pages={13--32},
  month={Mar},
  year={2020}
}

@article{atzori2020fully,
  title={Fully-unsupervised embeddings-based hypernym discovery},
  author={Atzori, Maurizio and Balloccu, Simone},
  journal={Information},
  volume={11},
  number={5},
  pages={268},
  month={May},
  year={2020},
  publisher={MDPI},
  abstract="The hypernymy relation is the one occurring between an instance term and its general term (e.g., “lion” and “animal”, “Italy” and “country”). This paper we addresses Hypernym Discovery, the NLP task that aims at finding valid hypernyms from words in a given text, proposing HyperRank, an unsupervised approach that therefore does not require manually-labeled training sets as most approaches in the literature. The proposed algorithm exploits the cosine distance of points in the vector space of word embeddings, as already proposed by previous state of the art approaches, but the ranking is then corrected by also weighting word frequencies and the absolute level of similarity, which is expected to be similar when measuring co-hyponyms and their common hypernym. This brings us two major advantages over other approaches—(1) we correct the inadequacy of semantic similarity which is known to cause a significant performance drop and (2) we take into accounts multiple words if provided, allowing to find common hypernyms for a set of co-hyponyms—a task ignored in other systems but very useful when coupled with set expansion (that finds co-hyponyms automatically). We then evaluate HyperRank against the SemEval 2018 Hypernym Discovery task and show that, regardless of the language or domain, our algorithm significantly outperforms all the existing unsupervised algorithms and some supervised ones as well. We also evaluate the algorithm on a new dataset to measure the improvements when finding hypernyms for sets of words instead of singletons."
}

@inproceedings{balloccu2020you,
  title={How are you? Introducing stress-based text tailoring},
  author={Balloccu, Simone and Reiter, Ehud and Johnstone, Alexandra and Fyfe, Claire},
  booktitle={Proceedings of the Workshop on Intelligent Information Processing and Natural Language Generation (IntelLanG)@ECAI 2020},
  pages={62--70},
  month={Sept},
  year={2020}
}

@inproceedings{10.1145/3450614.3463602,
author = {Balloccu, Simone and Reiter, Ehud and Collu, Matteo G. and Sanna, Federico and Sanguinetti, Manuela and Atzori, Maurizio},
title = {Unaddressed challenges in persuasive dieting chatbots},
year = {2021},
isbn = {9781450383677},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3450614.3463602},
doi = {10.1145/3450614.3463602},
abstract = {Diet coaching is a behaviour change task which requires lots of interaction with patients. E-health apps gathered lots of interest in research and, recently, chatbots have been leveraged to address this task, with a focus on persuasion to motivate people towards behaviour change. In this paper, we take a look at current approaches in building persuasive dieting chatbots and expose a number of major unsolved challenges. We motivate them with evidence from previous work and show that current chatbots don’t approach certain scenarios properly, hence limiting their communication and persuasion capabilities.},
booktitle = {Adjunct Proceedings of the 29th ACM Conference on User Modeling, Adaptation and Personalization},
pages = {392–395},
numpages = {4},
keywords = {challenges, chatbots, conversational agents, diet, diet coaching, natural language generation, persuasion},
location = {Utrecht, Netherlands},
series = {UMAP '21}
}



@inproceedings{sdaih23,
author="Kumar, Vivek and Balloccu, Simone and Wu, Zixiu and Reiter, Ehud and Helaoui, Rim and Reforgiato Recupero, Diego and Riboni, Daniele",
title="Data Augmentation for Reliability and Fairness in Counselling Quality Classification",
booktitle="Proceedings of the 1st Workshop on Scarce Data in Artificial Intelligence for Healthcare - SDAIH @ IJCAI 2022",
year="2022",
month="Jul",
pages="23-28",
publisher="SciTePress",
organization="INSTICC",
doi={10.5220/0011531400003523},
isbn={978-989-758-629-3},
}

@inproceedings{balloccu-reiter-2022-beyond,
    title = "Beyond calories: evaluating how tailored communication reduces emotional load in diet-coaching",
    author = "Balloccu, Simone  and
      Reiter, Ehud",
    booktitle = "Proceedings of the 2nd Workshop on Human Evaluation of NLP Systems (HumEval)",
    month = "May",
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.humeval-1.5",
    doi = "10.18653/v1/2022.humeval-1.5",
    pages = "42--53",
    abstract = "Dieting is a behaviour change task that is difficult for many people to conduct successfully. This is due to many factors, including stress and cost. Mobile applications offer an alternative to traditional coaching. However, previous work on apps evaluation only focused on dietary outcomes, ignoring users{'} emotional state despite its influence on eating habits. In this work, we introduce a novel evaluation of the effects that tailored communication can have on the emotional load of dieting. We implement this by augmenting a traditional diet-app with affective NLG, text-tailoring and persuasive communication techniques. We then run a short 2-weeks experiment and check dietary outcomes, user feedback of produced text and, most importantly, its impact on emotional state, through PANAS questionnaire. Results show that tailored communication significantly improved users{'} emotional state, compared to an app-only control group.",
}

@INPROCEEDINGS{9746035,
  author={Wu, Zixiu and Balloccu, Simone and Kumar, Vivek and Helaoui, Rim and Reiter, Ehud and Reforgiato Recupero, Diego and Riboni, Daniele},
  booktitle={ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Anno-MI: A Dataset of Expert-Annotated Counselling Dialogues}, 
  year={2022},
  volume={},
  number={},
  pages={6177-6181},
  keywords={Employee welfare;Annotations;Conferences;Medical treatment;Signal processing;Data collection;Natural language processing;Counselling;Motivational Interviewing;Dialogue;Natural Language Processing;Dataset},
  doi={10.1109/ICASSP43922.2022.9746035}}

@inproceedings{balloccu-reiter-2022-comparing,
    selected = {true},
    title = "Comparing informativeness of an {NLG} chatbot vs graphical app in diet-information domain",
    author = "Balloccu, Simone  and
      Reiter, Ehud",
    booktitle = "Proceedings of the 15th International Conference on Natural Language Generation",
    month = "Jul",
    year = "2022",
    address = "Waterville, Maine, USA and virtual meeting",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.inlg-main.13",
    pages = "156--185",
    abstract = "Visual representation of data like charts and tables can be challenging to understand for readers. Previous work showed that combining visualisations with text can improve the communication of insights in static contexts, but little is known about interactive ones. In this work we present an NLG chatbot that processes natural language queries and provides insights through a combination of charts and text. We apply it to nutrition, a domain communication quality is critical. Through crowd-sourced evaluation we compare the informativeness of our chatbot against traditional, static diet-apps. We find that the conversational context significantly improved users' understanding of dietary data in various tasks, and that users considered the chatbot as more useful and quick to use than traditional apps.",
}

@inproceedings{wu-etal-2022-towards-context,
    title = "Towards In-Context Non-Expert Evaluation of Reflection Generation for Counselling Conversations",
    author = "Wu, Zixiu  and
      Balloccu, Simone  and
      Helaoui, Rim  and
      Recupero, Diego Reforgiato  and
      Riboni, Daniele",
    booktitle = "Proceedings of the 2nd Workshop on Natural Language Generation, Evaluation, and Metrics (GEM)",
    month = "Dec",
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.gem-1.9",
    doi = "10.18653/v1/2022.gem-1.9",
    pages = "116--124",
    abstract = "Reflection is an essential counselling strategy, where the therapist listens actively and responds with their own interpretation of the client{'}s words. Recent work leveraged pre-trained language models (PLMs) to approach reflection generation as a promising tool to aid counsellor training. However, those studies used limited dialogue context for modelling and simplistic error analysis for human evaluation. In this work, we take the first step towards addressing those limitations. First, we fine-tune PLMs on longer dialogue contexts for reflection generation. Then, we collect free-text error descriptions from non-experts about generated reflections, identify common patterns among them, and accordingly establish discrete error categories using thematic analysis. Based on this scheme, we plan for future work a mass non-expert error annotation phase for generated reflections followed by an expert-based validation phase, namely {``}whether a coherent and consistent response is a good reflection{''}.",
}

@article{wu2023creation,
  title={Creation, Analysis and Evaluation of AnnoMI, a Dataset of Expert-Annotated Counselling Dialogues},
  author={Wu, Zixiu and Balloccu, Simone and Kumar, Vivek and Helaoui, Rim and Reforgiato Recupero, Diego and Riboni, Daniele},
  journal={Future Internet},
  volume={15},
  number={3},
  pages={110},
  month={March},
  year={2023},
  publisher={MDPI}
}

@INPROCEEDINGS{10193140,
  author={Susaiyah, Allmin and Härmä, Aki and Balloccu, Simone and Reiter, Ehud and Petković, Milan},
  booktitle={2023 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW)}, 
  title={Smart Selection of Useful Insights from Wearables}, 
  year={2023},
  month={June},
  volume={},
  number={},
  pages={1-4},
  doi={10.1109/ICASSPW59220.2023.10193140}
}

@inproceedings{wu-etal-2023-experts,
    selected = {true},
    title = "Are Experts Needed? On Human Evaluation of Counselling Reflection Generation",
    author = "Wu, Zixiu  and
      Balloccu, Simone  and
      Reiter, Ehud  and
      Helaoui, Rim  and
      Reforgiato Recupero, Diego  and
      Riboni, Daniele",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = "Jul",
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.382",
    doi = "10.18653/v1/2023.acl-long.382",
    pages = "6906--6930",
    abstract = "Reflection is a crucial counselling skill where the therapist conveys to the client their interpretation of what the client said. Language models have recently been used to generate reflections automatically, but human evaluation is challenging, particularly due to the cost of hiring experts. Laypeople-based evaluation is less expensive and easier to scale, but its quality is unknown for reflections. Therefore, we explore whether laypeople can be an alternative to experts in evaluating a fundamental quality aspect: coherence and context-consistency. We do so by asking a group of laypeople and a group of experts to annotate both synthetic reflections and human reflections from actual therapists. We find that both laypeople and experts are reliable annotators and that they have moderate-to-strong inter-group correlation, which shows that laypeople can be trusted for such evaluations. We also discover that GPT-3 mostly produces coherent and consistent reflections, and we explore changes in evaluation results when the source of synthetic reflections changes to GPT-3 from the less powerful GPT-2.",
}

@inproceedings{balloccu-etal-2024-leak,
    selected={true},
    title = "Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source {LLM}s",
    author = "Balloccu, Simone  and
      Schmidtov{\'a}, Patr{\'\i}cia  and
      Lango, Mateusz  and
      Dusek, Ondrej",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.eacl-long.5",
    pages = "67--93",
    abstract = "Natural Language Processing (NLP) research is increasingly focusing on the use of Large Language Models (LLMs), with some of the most popular ones being either fully or partially closed-source. The lack of access to model details, especially regarding training data, has repeatedly raised concerns about data contamination among researchers. Several attempts have been made to address this issue, but they are limited to anecdotal evidence and trial and error. Additionally, they overlook the problem of indirect data leaking, where modelsare iteratively improved by using data coming from users. In this work, we conduct the first systematic analysis of work using OpenAI{'}s GPT-3.5 and GPT-4, the most prominently used LLMs today, in the context of data contamination. By analysing 255 papers and considering OpenAI{'}s data usage policy, we extensively document the amount of data leaked to these models during the first year after the model{'}s release. We report that these models have been globally exposed to ∼4.7M samples from 263 benchmarks. At the same time, we document a number of evaluation malpractices emerging in the reviewed papers, such as unfair or missing baseline comparisons and reproducibility issues. We release our results as a collaborative project on https://leak-llm.github.io/, where other researchers can contribute to our efforts.",
}